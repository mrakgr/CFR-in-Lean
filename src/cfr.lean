import helpers

def regret_match {n : nat} (a : array n rat) :=
    let sum := a.foldl 0 (fun a s, max a 0 + s) in
    if sum = 0 then have v : rat, from 1 / n, array.init n (fun _, v)
    else a.map (fun a, max a 0 / sum)

structure Node {ğ”¸ : Type*} (actions : Î£ (n : nat), fin n â†’ ğ”¸) := mk :: 
    (strategy_sum : array actions.1 rat) 
    (regret_sum : array actions.1 rat)

def Infosets {â„ ğ”¸ : Type*} [lt : has_lt â„] (ha : HistoryToActions â„ ğ”¸) 
    := drbmap â„ (Node âˆ˜ ha) lt.lt

def Node_from_actions {ğ”¸ : Type*} (actions : Actions ğ”¸) := 
    {Node . 
        strategy_sum := array.init actions.1 (fun _, 0), 
        regret_sum := array.init actions.1 (fun _, 0)
        }

def response {â„ ğ”¸ : Type*} [lt : has_lt â„] [decidable_rel lt.lt]
        (ha : HistoryToActions â„ ğ”¸)
        (is_updateable : bool) (one_probability two_probability : rat) (h : â„)
        (next : ğ”¸ â†’ rat â†’ state (Infosets ha) rat)
        : state (Infosets ha) rat := âŸ¨ fun infosets,
    let (âŸ¨ h' , nodeâŸ© , infosets) := memoize infosets (fun h, Node_from_actions $ ha h) h in
    let action_probability := regret_match node.regret_sum in
    let âŸ¨ action_utility, infosets âŸ© := 
        actions_map_foldl2 (ha h').2 action_probability 
            infosets (fun action action_probability infosets, 
                if action_probability = 0 âˆ§ two_probability = 0 then (0, infosets) -- the pruning optimization
                else (next action (one_probability * action_probability)).run infosets
                ) in
    let action_utility_weighted_sum := 
        @nat.foldl.fin (fun i, rat) (ha h').1 0 
            (fun i s, s + action_utility.read i * action_probability.read i) in
    let infosets := 
        match is_updateable with
        | tt := 
            let add (f : â„š â†’ â„š) (a b : array (ha h').1 â„š) := array.mapâ‚‚ (fun s x, s + f x) a b in 
            infosets.insert h' {
                strategy_sum := add (fun action_probability, one_probability * action_probability) node.strategy_sum action_probability,
                regret_sum := add (fun action_utility, two_probability * (action_utility - action_utility_weighted_sum)) node.regret_sum action_utility
                }
        | ff := infosets
        end in

    (-action_utility_weighted_sum, infosets)
    âŸ©

def chance {â„ ğ”¸ Î” : Type*} [has_lt â„]
        (ha : HistoryToActions â„ ğ”¸) 
        (dice : Î£ n, fin n â†’ rat Ã— Î”)
        (one_probability : rat) 
        (next : Î” â†’ rat â†’ state (Infosets ha) rat)
        : state (Infosets ha) rat := âŸ¨ fun infosets, 
    actions_foldl dice ((0 : rat), infosets) (
        fun âŸ¨ dice_probability, diceâŸ© âŸ¨ util_sum, infosets âŸ© , 
            let (util, infosets) := (next dice (one_probability * dice_probability)).run infosets in
            (util_sum + util * dice_probability, infosets)
        )
    âŸ© 

def chance_uniform {â„ ğ”¸ Î” : Type*} [has_lt â„]
        (ha : HistoryToActions â„ ğ”¸) 
        (dice : Actions Î”)
        (one_probability : rat) 
        (next : Î” â†’ rat â†’ state (Infosets ha) rat)
        : state (Infosets ha) rat :=
    let dice_probability := 1 / dice.1 in
    chance ha âŸ¨ dice.1 , fun i, âŸ¨ dice_probability, dice.2 i âŸ© âŸ© one_probability next

def terminal {â„ ğ”¸ : Type*} [has_lt â„]
        (ha : HistoryToActions â„ ğ”¸)
        (reward : rat)
        : state (Infosets ha) rat := pure reward